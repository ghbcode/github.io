{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes, MLE and MAP\n",
    "\n",
    "First a little Baye's revision.\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "<br>\n",
    "$$Posterior = \\frac{Likelihood * Prior}{Evidence}$$\n",
    "<br>\n",
    "$$Posterior = \\frac{Likelihood * Prior}{some constant}$$\n",
    "<br>\n",
    "$$Posterior \\propto Likelihood * Prior$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE\n",
    "\\documentclass{article}\n",
    "\\usepackage{amsmath} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning you have many observations, call them $X$ (and we have $Y$ actually), and you try to fit a model to your data. The parameters of your model are referred to as $\\theta$. So in terms of the above we have: \n",
    "<br>\n",
    "$$P(\\theta|X) \\propto P(X|\\theta) * P(\\theta)$$\n",
    "<br>\n",
    "And if you simply want to focus on the likelihood term you will want to figure out the $\\theta$ that will maximize your likelihood. This is known as MLE (Maximum Likelihood Estimation). So then MLE is defined by\n",
    "<br>\n",
    "$$\\theta_{MLE}=\\quad \\underset{\\theta}{\\mathrm{argmax}}\\quad P(X|\\theta)$$\n",
    "<br>\n",
    "Often times we make the assumption that the individual $x_i$'s are i.i.d (independent and identically distritubed) so that \n",
    "<br>\n",
    "$$\\theta_{MLE}=\\quad \\underset{\\theta}{\\mathrm{argmax}}\\quad P(X|\\theta)$$\n",
    "$$\\theta_{MLE}= \\underset{\\theta}{\\mathrm{argmax}}\\quad \\prod_{i=1}^{D} P(x_i|\\theta)$$\n",
    "<br>\n",
    "Lastly, take note that as you expand the expression on the RHS, you are multiplying by numbers < 1 and ultimately it is easier to carry out the maximization on the log of the product. Log is a monotonically increasing function and $log(a*b) = log(a) + log(b)$. Since log is monotonically increasing the max of the log of a function occurs at the same location as the max of the function itself. One more twist, if we minimize the -log it turns out to be easier to solve and gives the same solution as maximizing the log (of the likelihood/function). \n",
    "<br>\n",
    "$$\\theta_{MLE}=\\quad \\underset{\\theta}{\\mathrm{argmin}}\\quad -log P(X|\\theta)\\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad -log \\prod_{i=1}^{D} P(x_i|\\theta) \\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad -\\sum_{i=1}^{D} log  P(x_i|\\theta)\n",
    "$$\n",
    "<br>\n",
    "From here, we need to pick a likelihood function and use optimization to compute the optimal $\\theta$. Let's say that we picked a Gaussian distribution for $X$, i.e. $X \\approx N(\\mu=0, \\sigma^2)$. So we would have:\n",
    "<br>\n",
    "$$\\theta_{MLE}= \\underset{\\theta}{\\mathrm{argmin}}\\quad - \\sum_{i=1}^{D} log  \\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(\\frac{-(x_i - 0)^2}{2\\sigma^2})\\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad - \\sum_{i=1}^{D} log [\\frac{1}{\\sqrt{2\\pi\\sigma^2}}] + log [exp(\\frac{-(x_i)^2}{2\\sigma^2})]\\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad - \\sum_{i=1}^{D} [log(1)-log(2\\pi\\sigma^2)^{1/2} - \\frac{x_i^2}{2\\sigma^2}]\\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad \\sum_{i=1}^{D} [0+\\frac{log(2\\pi\\sigma^2)}{2} + \\frac{x_i^2}{2\\sigma^2}]\\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad \\sum_{i=1}^{D} \\frac{log(2\\pi\\sigma^2)}{2} + \\sum_{i=1}^{D} \\frac{x_i^2}{2\\sigma^2}\\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad \\frac{D}{2}log(2\\pi\\sigma^2) + \\frac{1}{2\\sigma^2} \\sum_{i=1}^{D} x_i^2\\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad someconstant + \\frac{1}{2\\sigma^2} ||x||_{2}^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP\n",
    "\n",
    "MAP stands for Maximum A Posteriori and what it does isn that it assigns a probability density to the prior, $P(\\theta)$. So using the same logic as above we have: \n",
    "<br>\n",
    "$$\\theta_{MAP}=\\quad \\underset{\\theta}{\\mathrm{argmin}}\\quad -log P(X|\\theta)P(\\theta) \\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad -log \\prod_{i=1}^{D} P(x_i|\\theta)P(\\theta) \\\\\n",
    "= \\underset{\\theta}{\\mathrm{argmin}}\\quad -\\sum_{i=1}^{D} log  P(x_i|\\theta)P(\\theta) \\\\\n",
    "$$\n",
    "<br>\n",
    "In the simplest case imagine that $P(\\theta)$ is constant; so $P(\\theta)$ is say, uniform. In our minimization problem, multiplying $P(X|\\theta)$ by a constant does not change the optimal value for $\\theta$ and therefore \n",
    "<br>\n",
    "$$\\theta_{MAP}=\\theta_{MLE}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following links provide more details on the above:<br>\n",
    "https://en.wikipedia.org/wiki/Posterior_probability<br>\n",
    "https://wiseodd.github.io/techblog/2017/01/01/mle-vs-map/\n",
    "\n",
    "<br><br>\n",
    "# Key Take Away\n",
    "<br>\n",
    "Produce only a point estimate using a distribution for the likelihood and, in case of MAP, use prior knowledge on the distribution of the parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
