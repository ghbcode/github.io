{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "<br>\n",
    "In this case your data *D* is not labeled so what can you do with it? \n",
    "* learn structure in the data such a groups or clusters\n",
    "* help find features; for example find \"centroids\" of clusters to use as prototypes. So you could use the similarity to each centroid as a feature.\n",
    "<br>\n",
    "\n",
    "Unsupervised learning relies on what are called similarity or dissimilarity measures. These apply as:\n",
    "* between two points\n",
    "* between a point and a cluster\n",
    "* between two clusters\n",
    "<br><br>\n",
    "\n",
    "### Dissimilarity Measures\n",
    "<br>\n",
    "Let $\\delta(x_{ij}, x_{i'j})$ denote the dissimilarity measure between points $x_{ij}$ and $x_{i'j}$. In this case these are some of the different dissimilarity measures:\n",
    "* euclidean distance, i.e. $(x_{ij} - x_{i'j})^2$\n",
    "* l1 norm, i.e. |$x_{ij} - x_{i'j}$|\n",
    "* for categorical features there is the Hamming Distance, i.e. the number of features that are different. $= \\sum_{j=1}^D (x_{ij} \\ne x_{i'j})$\n",
    "* any monotonically increasing function \n",
    "<br>\n",
    "\n",
    "### Similarity Measures\n",
    "<br>\n",
    "Likewise, for similarity measures you can have $\\delta(x_{ij}, x_{i'j})$ be:\n",
    "* any monotonically decreasing function, ex: = $e^{\\frac{d_{ii'}^2}{\\sigma^2}}$\n",
    "* for binary features, the percentage of shared features\n",
    "  $$s(x_i,x_{i'}) = \\frac{x_i^Tx_{i'}}{x_i^Tx_i + x_{i'}^Tx_{i'} - x_i^Tx_{i'}}$$\n",
    "* for features with physical dependence (temporal or spatial), there is the Pearson correlation coefficient\n",
    "  $$r_{ii'} = \\frac{\\sum_{j=1}^D (x_{ij} - x_i)(x_{i'j}-x_{i'})}{[\\sum_{j=1}^D (x_{ij} - x_i)^2 \\sum_{j=1}^D(x_{i'j}-x_{i'})^2]^{1/2}} $$ \n",
    "<br><br>\n",
    "\n",
    "A common tool used for unsupervised learning is the \"[Dendogram](https://en.wikipedia.org/wiki/Dendrogram)\" that illustrates the clustering for a data set given a dissimilarity measure. There are two approaches for building a dendogram:\n",
    "* aglomerative(bottom up) \n",
    "* divisive (top down)\n",
    "<br><br>\n",
    "\n",
    "### Hierarchical Agglomerative Clustering (HAC)\n",
    "Let $\\gamma_{jk}$ be the distance or dissimilarity between clusters $C_j$ and $C_k$ and $\\hat{K}$ be the current number of clusters.\n",
    "1. Choose halting condition H.C.\n",
    "2. Initialize $\\hat{K}$=N, m=1 and cluster $C_i$ = {$x_i$}, i.e. each point is its own cluster\n",
    "3. Repeat until H.C. is met\n",
    "4. Find nearest (most similar) pair of clusters, $\\gamma'$ = min $\\gamma_{jk}$\n",
    "5. If H.C. condition is based on $\\gamma'$, test for it and halt if true\n",
    "6. Apply merge rule, so merge $C_j$ with $C_k$ into $C_l$\n",
    "7. Update, $\\hat{K}$ = $\\hat{K-1}$, m = m+1\n",
    "8. If H.C. is based on $\\hat{K}$, test for it and halt if true\n",
    "9. Output final clusters $C_l$, l=1, 2,$\\hat{K}_{final}$\n",
    "    * if $\\hat{K}_{final}$=1 then resulting hierarchy is a dendogram\n",
    "<br>\n",
    "\n",
    "Some useful dissimilarity measures between clusters $C_j$ and $C_k$ include:\n",
    "* $\\gamma_{mean}(C_j,C_k) = ||C_j - C_k||_2$\n",
    "* $\\gamma_{min}(C_j,C_k) = min||C_j - C_k||_2$\n",
    "  * This measure is used by the **\"Nearest Neighbor\"** algorithm\n",
    "* $\\gamma_{max}(C_j,C_k) = max||C_j - C_k||_2$\n",
    "  * This measure is used by the **\"Farthest Neighbor\"** algorithm\n",
    "* $\\gamma_{average}(C_j,C_k) = \\frac{1}{N_jN_k}\\sum_j \\sum_k ||C_j - C_k||_2$, where $N_j$ are the number of points in $C_j$\n",
    "<br>\n",
    "\n",
    "### Resources\n",
    "* Complete linkage clustering example: https://onlinecourses.science.psu.edu/stat555/node/86\n",
    "* NLP HAC example: https://nlp.stanford.edu/IR-book/html/htmledition/hierarchical-agglomerative-clustering-1.html\n",
    "* Great post on usl: https://sdsawtelle.github.io/blog/output/week8-andrew-ng-machine-learning-with-python.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
