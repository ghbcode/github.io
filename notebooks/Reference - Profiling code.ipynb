{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: default\n",
    "title: Notes and samples on Python Topics\n",
    "description: posted by ghbcode on 2013/07/19\n",
    "---\n",
    "\n",
    "## Troubleshooting Code - timing, profiling and tracing\n",
    "<br>\n",
    "If you are using an IDE such as Eclipse to debug your code then you have a rich set of tools at your disposal. If you are working in the terminal or in Jupyter then here are some useful tools to help you troubleshoot your code. Below is the function called \"run_experiment\" that computes the eigenvalues of a K x K input matrix. Before we get started though, you may have to install the following packages.\n",
    "<br>\n",
    "\n",
    "> pip install timeit <br>\n",
    "> pip install line_profiler  <br>\n",
    "> pip install memory_profiler  <br>\n",
    "> pip install pdb <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest eigenvalue calculated: 5.344516334386579\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eigvals\n",
    "\n",
    "def run_experiment(niter=100, K=10):\n",
    "    results = []\n",
    "    for i in range(niter):\n",
    "        mat = np.random.randn(K, K)\n",
    "        max_eigenvalue = np.abs(eigvals(mat)).max()\n",
    "        results.append(max_eigenvalue)\n",
    "    return results\n",
    "some_results = run_experiment()\n",
    "print(\"Largest eigenvalue calculated: {0}\".format(np.max(some_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Code\n",
    "\n",
    "You can use the \"time\" package to simply time a block of code as is done below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.004379987716674805\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "run_experiment(niter=50, K=5)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Execution time: {0}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get more information about how long a certain function takes to run you can use the \"timeit\" package as per below where you can specify to take an average over three runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.5 ms ± 1.89 ms per loop (mean ± std. dev. of 3 runs, 10 loops each)\n",
      "Execution time: 1.0858049392700195\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "t0 = time.time()\n",
    "\n",
    "%timeit -r 3 run_experiment(niter=200, K=15)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Execution time: {0}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8516999999999999\n"
     ]
    }
   ],
   "source": [
    "print((26.5e-3 + 1.89e-3) * 3 * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timeit package estimated an average run time of 26.5ms (+- 1.89ms) for the run_experiment(niter=200, K=15) function over the course of three runs with 10 loops each. That is roughly .85 seconds although timing timeit recorded a total of 1.09 seconds. It seems feasible that a quarter of a second was spent by the os or system dealing with housekeeping. So now you have an idea how long your function takes to run on average given a certain set of inputs. So what if you want to find out even more information? In this case you can use the \"line_profiler\" package. Note that you do not need to update the code with the **@profile** decorator.\n",
    "<br>\n",
    "\n",
    "### Profiling Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f run_experiment run_experiment(niter=150, K=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by the output, 86% of the time was spent calculating the eigenvalues. If you want to go deeper you can ask lprun to profile a function inside of run_experiment as is done below. Instead of profiling run_experiment itself, you are going to profile the eigenvals() function.<br>\n",
    "\n",
    "![profiling result](profiling01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f eigvals run_experiment(niter=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you can see that roughly 38% of the time is spent in the function \"\"\n",
    "<br>\n",
    "\n",
    "![profiling 2](profiling02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Profiling Code\n",
    "<br>\n",
    "If instead of time you want to see how much memory a particular function is using, then you can invoke the \"memit\" profiler tool. Below, out of three runs, the memory profiler calculated a peak memory usage of 49 MiB for the run_experiment() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "peak memory: 49.39 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "%memit -r 3 run_experiment(niter=200, K=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing Code \n",
    "<br>\n",
    "Now if you want to trace the code also known as debugging, then you can use the \"pdb\" package. This will allow you to step through the code and see what is going on inside of it. For a list of commands you can refer to the [python debugger page](https://docs.python.org/2/library/pdb.html)<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-9-363c57a97903>(2)<module>()->None\n",
      "-> pdb.set_trace()\n",
      "(Pdb) s\n",
      "> /Users/gonzalobriceno/venvp3/lib/python3.5/site-packages/IPython/core/interactiveshell.py(2913)run_code()\n",
      "-> sys.excepthook = old_excepthook\n",
      "(Pdb) continue\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6156927800854413,\n",
       " 1.8905887143646258,\n",
       " 1.7111310677162486,\n",
       " 1.5509143737840982,\n",
       " 2.9387394467077232]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdb\n",
    "pdb.set_trace()\n",
    "run_experiment(niter=5, K=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
